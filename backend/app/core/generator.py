from google import genai
from google.genai import types
import json
import os
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_root = os.path.dirname(os.path.dirname(current_dir))
env_path = os.path.join(backend_root, '.env')
load_dotenv(env_path)
print(f"ğŸ” .envèª­ã¿è¾¼ã¿ãƒ‘ã‚¹: {env_path}")
print(f"ğŸ” .envãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: {os.path.exists(env_path)}")

def llm_generator(user_goal: str) -> dict:
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦èª­ã¿è¾¼ã‚€
    current_dir = os.path.dirname(os.path.abspath(__file__))
    backend_root = os.path.dirname(os.path.dirname(current_dir))
    project_root = os.path.dirname(backend_root)
    system_prompt_path = os.path.join(project_root, "backend/config/system_prompt.json")
    
    with open(system_prompt_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # "system_prompt"ã®å€¤ã‚’å–ã‚Šå‡ºã™
    system_prompt = data["system_prompt"] 
    
    # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
    print("ğŸ” å…¨ç’°å¢ƒå¤‰æ•°ç¢ºèª:")
    for key in ['GOOGLE_APPLICATION_CREDENTIALS', 'GOOGLE_CLOUD_PROJECT', 'FIREBASE_SERVICE_ACCOUNT_KEY']:
        value = os.getenv(key, 'NOT_SET')
        print(f"  {key}: {value}")
    
    # Vertex AIç”¨ã®èªè¨¼æƒ…å ±ã‚’å¼·åˆ¶çš„ã«è¨­å®š
    project_id = os.getenv('GOOGLE_CLOUD_PROJECT', 'gcp-ai-461501')
    
    # å¤ã„å€¤ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã¯å¼·åˆ¶çš„ã«æ­£ã—ã„å€¤ã‚’è¨­å®š
    vertex_ai_credentials = 'backend/config/vertex-ai-key.json'
    
    print(f"ğŸ” Vertex AI Project: {project_id}")
    print(f"ğŸ” Vertex AI Credentials (å¼·åˆ¶è¨­å®š): {vertex_ai_credentials}")
    
    # çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
    if vertex_ai_credentials and not os.path.isabs(vertex_ai_credentials):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        backend_root = os.path.dirname(os.path.dirname(current_dir))
        project_root = os.path.dirname(backend_root)
        vertex_ai_credentials = os.path.join(project_root, vertex_ai_credentials)
        
        # ç’°å¢ƒå¤‰æ•°ã‚’å¼·åˆ¶çš„ã«æ›´æ–°
        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = vertex_ai_credentials
        print(f"ğŸ” Vertex AIçµ¶å¯¾ãƒ‘ã‚¹: {vertex_ai_credentials}")
        print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª: {os.path.exists(vertex_ai_credentials)}")
        
        if not os.path.exists(vertex_ai_credentials):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vertex_ai_credentials}")
            print(f"ğŸ“ config ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹:")
            config_dir = os.path.dirname(vertex_ai_credentials)
            if os.path.exists(config_dir):
                for file in os.listdir(config_dir):
                    print(f"  - {file}")
            else:
                print(f"âŒ config ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {config_dir}")
    
    client = genai.Client(
        vertexai=True,
        project=project_id,
        location="us-central1",  # ä¸€èˆ¬çš„ã«åˆ©ç”¨å¯èƒ½ãªãƒªãƒ¼ã‚¸ãƒ§ãƒ³
    )

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›®æ¨™ã‚’é©åˆ‡ãªå½¢å¼ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã‚€
    user_prompt = f"ä»¥ä¸‹ã®å¤§ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã®å…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\nå¤§ç›®æ¨™ï¼š{user_goal}"

    model = "gemini-2.5-flash-preview-05-20"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text=user_prompt)
            ]
        )
    ]

    generate_content_config = types.GenerateContentConfig(
        temperature = 0.7,
        top_p = 0.9,
        max_output_tokens = 65535,
        safety_settings = [
            types.SafetySetting(
                category="HARM_CATEGORY_HATE_SPEECH",
                threshold="OFF"
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                threshold="OFF"
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                threshold="OFF"
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_HARASSMENT",
                threshold="OFF"
            )
        ],
        response_mime_type = "application/json",
        response_schema = {
            "type": "OBJECT",
            "properties": {
                "goal": {"type": "STRING"},
                "estimated_period": {"type": "STRING"},
                "mid_goals": {
                    "type": "ARRAY",
                    "items": {
                        "type": "OBJECT",
                        "properties": {
                            "id": {"type": "INTEGER"},
                            "title": {"type": "STRING"},
                            "description": {"type": "STRING"},
                            "estimated_duration": {"type": "STRING"},
                            "small_goals": {
                                "type": "ARRAY",
                                "items": {
                                    "type": "OBJECT",
                                    "properties": {
                                        "id": {"type": "INTEGER"},
                                        "title": {"type": "STRING"},
                                        "description": {"type": "STRING"},
                                        "tasks": {
                                            "type": "ARRAY",
                                            "items": {"type": "STRING"}
                                        },
                                        "success_criteria": {"type": "STRING"}
                                    }
                                }
                            }
                        }
                    }
                },
                "tips": {
                    "type": "ARRAY",
                    "items": {"type": "STRING"}
                }
            }
        },
        system_instruction=[types.Part.from_text(text=system_prompt)],
    )

    result = client.models.generate_content(
        model = model,
        contents = contents,
        config = generate_content_config,
    )
    
    result_text = result.text
    
    try:
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ§‹é€ ã‚’ç¢ºèª
        result_json = json.loads(result_text)
        return result_json
    except json.JSONDecodeError as e:
        # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚€è¾æ›¸ã‚’è¿”ã™
        return {
            "error": "JSON parse error",
            "message": str(e),
            "raw_response": result_text
        }


def main():
    user_goal = "TOEIC 800ç‚¹ã‚’å–å¾—ã™ã‚‹"
    result = llm_generator(user_goal)
    print("Result:", json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()